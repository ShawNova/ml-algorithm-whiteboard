{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "model_name = os.getenv('OPENAI_MODEL')\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm just a program, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 13, 'total_tokens': 37, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-0ceb9cae-79ff-43e2-809a-8ae903435691-0', usage_metadata={'input_tokens': 13, 'output_tokens': 24, 'total_tokens': 37, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\")\n",
    "model.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple LLM Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hello\n",
      "!\n",
      " How\n",
      " can\n",
      " I\n",
      " assist\n",
      " you\n",
      " today\n",
      "?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OpenAI's chat completion message, including roles as developers, users, and assistant\n",
    "# langchain-core provides messages for developers, users, and assistant\n",
    "# langchain also support OpenAI API's message format\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage( \"Hello, how are you?\"),\n",
    "    HumanMessage(\"hi!\"),\n",
    "]\n",
    "\n",
    "# model.invoke(messages)\n",
    "\n",
    "for token in model.stream(messages):\n",
    "    print(token.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='translate the following text into French', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hello, how are you?', additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Bonjour\n",
      ",\n",
      " comment\n",
      " Ã§a\n",
      " va\n",
      " ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# langchain provides prompt template\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "sys_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"translate the following text into {language}\"),\n",
    "        (\"user\", \"{text}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt = sys_template.invoke(\n",
    "    {\n",
    "        \"language\": \"French\",\n",
    "        \"text\": \"Hello, how are you?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt)\n",
    "\n",
    "for token in model.stream(prompt):\n",
    "    print(token.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to build a conversation?\n",
    "\n",
    "### 1. Naive way: record messages manually.\n",
    "```python\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "Messages = [\n",
    "    HumanMessage(\"I'm Tom\"),\n",
    "    AIMessage(\"Hello Tom!\"),\n",
    "    HumanMessage(\"What's my name?\"),\n",
    "]\n",
    "\n",
    "# AIMessage(content=\"Your name is Tom\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. memory with langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "workflow = StateGraph(state_schema=MessagesState)\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    response = model.invoke(state['messages'])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_node(\"model\", call_model)\n",
    "workflow.add_edge(START, \"model\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "query = \"Hi. I'm Tom. How are you doing?\"\n",
    "\n",
    "msg_input = [HumanMessage(query)]\n",
    "response = app.invoke({\"messages\": msg_input}, config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"Hi. I'm Tom. How are you doing?\", additional_kwargs={}, response_metadata={}, id='f7a9b3c7-b2d8-472f-8b04-95b33244bd5d'),\n",
       "  AIMessage(content=\"Hi Tom! I'm just a program, but I'm here and ready to help you. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 17, 'total_tokens': 42, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-23628512-262e-44c4-9eba-7bdd274afae7-0', usage_metadata={'input_tokens': 17, 'output_tokens': 25, 'total_tokens': 42, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"Hi. I'm Tom. How are you doing?\", additional_kwargs={}, response_metadata={}, id='6608798d-40b7-4d44-b7d9-bb4a7f3008ec'),\n",
       "  AIMessage(content=\"Hi Tom! I'm here and ready to assist you. How can I help you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 59, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-a109a863-8ca6-464d-9d0d-ce6e91ac4dff-0', usage_metadata={'input_tokens': 59, 'output_tokens': 19, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='6da1bba6-51ef-4edd-b9a5-70c53705add4'),\n",
       "  AIMessage(content='Your name is Tom. How can I assist you today, Tom?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-86e14cee-5ee4-47ce-957e-1e155ec5b9c0-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='01a139b3-7f93-4596-9075-c3df0faf291c'),\n",
       "  AIMessage(content=\"Your name is Tom. If there's anything else you'd like to discuss or ask, feel free!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 115, 'total_tokens': 135, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-26164850-6b77-41c8-b6f3-2be7402675c9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 20, 'total_tokens': 135, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}, id='d6bc6cac-cf29-4f9d-b846-b0fcd2bf68a7'),\n",
       "  AIMessage(content='Your name is Tom. How can I assist you further?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 146, 'total_tokens': 159, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_06737a9306', 'finish_reason': 'stop', 'logprobs': None}, id='run-6e381ad0-5674-4e01-953e-8448a4a78de1-0', usage_metadata={'input_tokens': 146, 'output_tokens': 13, 'total_tokens': 159, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What's my name?\"\n",
    "msg_input = [query]\n",
    "response = app.invoke({\"messages\": msg_input}, config)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this way, the conversation is memorized in the checkpoint located in the memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is agent?\n",
    "\n",
    "An agent is a system that uses LLM to make human-like decisions and executions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financeRAG_acm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
